#!/usr/bin/env python3
"""
Lixun Robot - é—®ç­”è¿‡ç¨‹å®Œå…¨æ— æ—¥å¿—å¹²æ‰°çš„å‘½ä»¤è¡Œç‰ˆæœ¬
"""
import sys
import os
import subprocess
import importlib.util
from typing import List, Dict, Any
import logging
import warnings


def setup_selective_logging():
    """è®¾ç½®é€‰æ‹©æ€§æ—¥å¿—ï¼Œåªåœ¨åˆå§‹åŒ–é˜¶æ®µæ˜¾ç¤ºæ—¥å¿—"""
    # è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œä½†ä¸å®Œå…¨ç¦ç”¨
    logging.getLogger("langchain").setLevel(logging.WARNING)
    logging.getLogger("langsmith").setLevel(logging.WARNING)
    logging.getLogger("openai").setLevel(logging.WARNING)

    # ç¦ç”¨pydanticçš„ç‰¹å®šè­¦å‘Š
    warnings.filterwarnings("ignore", category=UserWarning, module="pydantic")
    warnings.filterwarnings("ignore", category=FutureWarning)


def check_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…ç¼ºå¤±çš„ä¾èµ–"""
    required_packages = {
        'fastapi': 'fastapi',
        'uvicorn': 'uvicorn',
        'langchain_core': 'langchain-core',
        'langchain_community': 'langchain-community',
        'langchain_openai': 'langchain-openai',
        'langchain_text_splitters': 'langchain-text-splitters',
        'langgraph': 'langgraph',
        'openai': 'openai',
        'faiss': 'faiss-cpu',
        'pypdf': 'pypdf',
        'docx': 'python-docx',
        'pydantic': 'pydantic',
        'loguru': 'loguru',
        'dotenv': 'python-dotenv',
        'dashscope': 'dashscope'
    }

    missing_packages = []
    for package_name, pip_name in required_packages.items():
        if importlib.util.find_spec(package_name) is None:
            missing_packages.append(pip_name)

    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("æ­£åœ¨å®‰è£…ä¾èµ–...")
        try:
            subprocess.run([
                               sys.executable, "-m", "uv", "pip", "install",
                               "--index-url", "https://pypi.tuna.tsinghua.edu.cn/simple"
                           ] + missing_packages, check=True)
            print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            return False
    else:
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")

    return True


def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    os.environ["PYTHONPATH"] = current_dir
    print(f"ğŸ“ é¡¹ç›®è·¯å¾„: {current_dir}")


def check_environment_variables():
    """æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡"""
    from dotenv import load_dotenv
    import os

    # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(override=True)

    required_vars = {
        'DASHSCOPE_API_KEY': 'DashScope APIå¯†é’¥',
    }

    missing_vars = []
    for var_name, description in required_vars.items():
        value = os.getenv(var_name)
        if not value:
            missing_vars.append(f"{var_name} ({description})")
        else:
            print(f"âœ… {var_name}: å·²è®¾ç½®")

    if missing_vars:
        print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        return False

    print("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    return True


class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨ - è‡ªåŠ¨åŠ è½½data/documentsä¸­çš„æ‰€æœ‰æ–‡ä»¶"""

    def __init__(self):
        # åœ¨æ–¹æ³•å†…éƒ¨å¯¼å…¥ï¼Œé¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
        from core.document_processor import DocumentProcessor
        from core.vector_store import VectorStoreManager
        from core.conversation_manager import ConversationManager

        self.document_processor = DocumentProcessor()
        self.vector_store = VectorStoreManager()
        self.conversation_manager = ConversationManager()
        self.chat_agent = None

    def load_all_documents(self):
        """åŠ è½½data/documentsä¸­çš„æ‰€æœ‰æ–‡æ¡£"""
        # åœ¨æ–¹æ³•å†…éƒ¨å¯¼å…¥ChatAgentï¼Œç¡®ä¿æ‰€æœ‰ä¾èµ–å·²åŠ è½½
        from chains.chat_agent import ChatAgent

        documents_dir = "data/documents"
        if not os.path.exists(documents_dir):
            print(f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {documents_dir}")
            return False

        supported_extensions = {'.pdf', '.docx', '.md', '.txt'}
        document_files = []

        # æ‰«ææ–‡æ¡£ç›®å½•
        for filename in os.listdir(documents_dir):
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext in supported_extensions:
                document_files.append(filename)

        if not document_files:
            print("âŒ åœ¨data/documentsç›®å½•ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶")
            return False

        print(f"ğŸ“š æ‰¾åˆ° {len(document_files)} ä¸ªæ–‡æ¡£æ–‡ä»¶:")
        for doc in document_files:
            print(f"   - {doc}")

        all_documents = []
        total_chunks = 0

        # å¤„ç†æ¯ä¸ªæ–‡æ¡£
        for filename in document_files:
            try:
                file_path = os.path.join(documents_dir, filename)
                file_ext = os.path.splitext(filename)[1].lower()[1:]  # å»æ‰ç‚¹å·

                print(f"ğŸ” å¤„ç†æ–‡æ¡£: {filename}")

                # æå–æ–‡æœ¬
                text = self.document_processor.extract_text(file_path, file_ext)

                # åˆ†å‰²æ–‡æ¡£
                documents = self.document_processor.split_documents(text, {
                    "filename": filename,
                    "file_type": file_ext
                })

                all_documents.extend(documents)
                total_chunks += len(documents)
                print(f"   âœ… æˆåŠŸå¤„ç†ï¼Œåˆ†å‰²ä¸º {len(documents)} ä¸ªç‰‡æ®µ")

            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
                continue

        if not all_documents:
            print("âŒ æ‰€æœ‰æ–‡æ¡£å¤„ç†å¤±è´¥")
            return False

        # åˆ›å»ºå‘é‡å­˜å‚¨
        print(f"\nğŸ“Š åˆ›å»ºå‘é‡ç´¢å¼•...")
        self.vector_store.create_vector_store(all_documents)
        self.vector_store.save_vector_store("data/vector_store")

        # åˆå§‹åŒ–èŠå¤©ä»£ç†
        self.chat_agent = ChatAgent(self.vector_store, self.conversation_manager)

        print(f"âœ… æ–‡æ¡£åŠ è½½å®Œæˆ! å…±å¤„ç† {len(document_files)} ä¸ªæ–‡ä»¶ï¼Œ{total_chunks} ä¸ªæ–‡æœ¬ç‰‡æ®µ")
        return True

    def chat_loop(self):
        """å‘½ä»¤è¡ŒèŠå¤©å¾ªç¯"""
        if not self.chat_agent:
            print("âŒ èŠå¤©ä»£ç†æœªåˆå§‹åŒ–")
            return

        conversation_id = "cli_session"

        print("\n" + "=" * 50)
        print("ğŸ¤– Lixun Robot èŠå¤©æœºå™¨äººå·²å°±ç»ª!")
        print("ğŸ’¡ æ”¯æŒçš„æŒ‡ä»¤:")
        print("  â€¢ è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯")
        print("  â€¢ è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
        print("  â€¢ è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("  â€¢ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("=" * 50)

        while True:
            try:
                user_input = input("\nğŸ’¬ ä½ çš„é—®é¢˜: ").strip()

                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§!")
                    break
                elif user_input.lower() == 'history':
                    self._show_conversation_history(conversation_id)
                elif user_input.lower() == 'clear':
                    self.conversation_manager.clear_conversation(conversation_id)
                    print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º")
                elif user_input:
                    self._process_chat(user_input, conversation_id)
                else:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

    def _show_conversation_history(self, conversation_id: str):
        """æ˜¾ç¤ºæ ¼å¼åŒ–çš„å¯¹è¯å†å²"""
        history = self.conversation_manager.get_conversation_history(conversation_id)
        if not history:
            print("ğŸ“ æš‚æ— å¯¹è¯å†å²")
            return

        print("\n" + "ğŸ“‹ å¯¹è¯å†å² ".ljust(50, "="))

        round_number = 1
        i = 0
        while i < len(history):
            # ç”¨æˆ·æé—®
            if i < len(history) and history[i]["role"] == "user":
                print(f"\nğŸ‘¤ ç¬¬{round_number}è½®æé—®:")
                print(f"   {history[i]['content']}")
                i += 1

            # AIå›ç­”
            if i < len(history) and history[i]["role"] == "assistant":
                print(f"ğŸ¤– å›ç­”:")
                answer = history[i]['content']
                print(f"   {answer}")

                # æ˜¾ç¤ºå¼•ç”¨ä¿¡æ¯
                if history[i].get("metadata", {}).get("citations"):
                    citations = history[i]["metadata"]["citations"]
                    print(f"   ğŸ“š å¼•ç”¨ {len(citations)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                i += 1

            round_number += 1

        print("=" * 50)

    def _process_chat(self, question: str, conversation_id: str):
        """å¤„ç†èŠå¤©è¯·æ±‚å¹¶ç¾åŒ–è¾“å‡º"""
        print("ğŸ’­ æ€è€ƒä¸­...", end="", flush=True)

        try:
            # ä¸´æ—¶ç¦ç”¨æ‰€æœ‰æ—¥å¿—è¾“å‡º
            import logging
            import loguru

            # ä¿å­˜åŸå§‹æ—¥å¿—çŠ¶æ€
            original_logging_level = logging.getLogger().level
            original_loguru_sinks = []

            # ç¦ç”¨æ ‡å‡†logging
            logging.disable(logging.CRITICAL)

            # ç¦ç”¨loguruçš„æ‰€æœ‰sink
            for handler_id in list(loguru.logger._core.handlers):
                original_loguru_sinks.append(handler_id)
                loguru.logger.remove(handler_id)

            result = self.chat_agent.chat(question, conversation_id)

            # æ¢å¤æ—¥å¿—è¾“å‡º
            logging.disable(logging.NOTSET)
            logging.getLogger().setLevel(original_logging_level)

            # é‡æ–°æ·»åŠ loguru sinkï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
            if not loguru.logger._core.handlers:
                loguru.logger.add(sys.stderr, level="INFO")

            print("\râœ… å›ç­”ç”Ÿæˆå®Œæˆ!" + " " * 20)  # æ¸…é™¤"æ€è€ƒä¸­"æç¤º

            # æ˜¾ç¤ºå›ç­”
            print(f"\nğŸ¤– {result['answer']}")

            # æ˜¾ç¤ºå¼•ç”¨ä¿¡æ¯ - ç¡®ä¿è¿™éƒ¨åˆ†å­˜åœ¨
            if result.get('citations'):
                print(f"\nğŸ“– å¼•ç”¨æ¥æº:")
                for citation in result['citations']:
                    filename = citation.get('metadata', {}).get('filename', 'æœªçŸ¥æ–‡ä»¶')
                    doc_content = citation['content'].strip()

                    # æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                    print(f"   ğŸ“„ æ¥è‡ªã€Š{filename}ã€‹:")
                    print(f"      {doc_content}")
                    print()  # ç©ºè¡Œåˆ†éš”

            # æ˜¾ç¤ºæ£€ç´¢ç»Ÿè®¡
            if result.get('retrieved_docs'):
                print(f"ğŸ” æœ¬æ¬¡æ£€ç´¢å‚è€ƒäº† {len(result['retrieved_docs'])} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

        except Exception as e:
            # æ¢å¤æ—¥å¿—è¾“å‡º
            import logging
            import loguru

            logging.disable(logging.NOTSET)
            if not loguru.logger._core.handlers:
                loguru.logger.add(sys.stderr, level="INFO")

            print(f"\râŒ å›ç­”ç”Ÿæˆå¤±è´¥!" + " " * 20)
            print(f"é”™è¯¯è¯¦æƒ…: {e}")

def main():
    """ä¸»å¯åŠ¨å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ Lixun Robot...")

    # è®¾ç½®é€‰æ‹©æ€§æ—¥å¿—
    setup_selective_logging()

    if not check_dependencies():
        print("âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡")
        input("æŒ‰å›è½¦é”®é€€å‡º...")
        return

    setup_environment()

    # æ·»åŠ ç¯å¢ƒå˜é‡æ£€æŸ¥
    if not check_environment_variables():
        print("âŒ ç¯å¢ƒå˜é‡é…ç½®å¤±è´¥")
        input("æŒ‰å›è½¦é”®é€€å‡º...")
        return

    try:
        # åˆå§‹åŒ–æ–‡æ¡£åŠ è½½å™¨
        loader = DocumentLoader()

        print("\nğŸ“¥ å¼€å§‹åŠ è½½æ–‡æ¡£...")
        if not loader.load_all_documents():
            print("âŒ æ–‡æ¡£åŠ è½½å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨èŠå¤©åŠŸèƒ½")
            input("æŒ‰å›è½¦é”®é€€å‡º...")
            return

        # å¯åŠ¨å‘½ä»¤è¡ŒèŠå¤©
        loader.chat_loop()

    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        input("æŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()