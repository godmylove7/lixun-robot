from typing import Dict, Any, List
from loguru import logger
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from pydantic import BaseModel

from core.llm_config import LLMConfig


class ChatState(BaseModel):
    question: str
    conversation_history: List[Dict[str, Any]]
    retrieved_docs: List[Document] = []
    answer: str = ""
    citations: List[Dict[str, Any]] = []


class ChatAgent:
    def __init__(self, vector_store_manager, conversation_manager):
        self.llm_config = LLMConfig()
        self.llm = self.llm_config.get_chat_model()
        self.vector_store = vector_store_manager
        self.conversation_manager = conversation_manager

        # æ„å»ºå·¥ä½œæµ
        self.workflow = self._build_workflow()

    def _build_workflow(self):
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        workflow = StateGraph(ChatState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("retrieve", self.retrieve_documents)
        workflow.add_node("generate_answer", self.generate_answer)

        # è®¾ç½®è¾¹
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "generate_answer")
        workflow.add_edge("generate_answer", END)

        return workflow.compile()

    def retrieve_documents(self, state: ChatState) -> Dict[str, Any]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        logger.info(f"Retrieving documents for question: {state.question}")

        # æ„å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
        enhanced_query = self._enhance_query(state.question, state.conversation_history)

        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = self.vector_store.similarity_search(enhanced_query, k=4)

        return {"retrieved_docs": retrieved_docs}

    def _enhance_query(self, question: str, history: List[Dict]) -> str:
        """åŸºäºå¯¹è¯å†å²å¢å¼ºæŸ¥è¯¢"""
        if not history:
            return question

        # è·å–æœ€è¿‘çš„å‡ ä¸ªç”¨æˆ·é—®é¢˜ä½œä¸ºä¸Šä¸‹æ–‡
        recent_questions = [
            msg["content"] for msg in history[-3:]
            if msg["role"] == "user"
        ]

        if recent_questions:
            context = " ".join(recent_questions[-2:])
            return f"{context} {question}"

        return question

    def generate_answer(self, state: ChatState) -> Dict[str, Any]:
        """ç”Ÿæˆå›ç­”"""
        logger.info("Generating answer with retrieved documents")

        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context_parts = []
        for i, doc in enumerate(state.retrieved_docs):
            filename = doc.metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')
            content_preview = doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content
            context_parts.append(f"ã€æ–‡æ¡£{i + 1} - æ¥è‡ªã€Š{filename}ã€‹ã€‘\n{content_preview}")

        context = "\n\n".join(context_parts)

        # æ„å»ºæ›´äººæ€§åŒ–çš„æç¤ºè¯
        prompt = ChatPromptTemplate.from_template("""
# è§’è‰²è®¾å®š
ä½ æ˜¯Lixun Robotï¼Œä¸€ä¸ªä¸“ä¸šä¸”å‹å¥½çš„çŸ¥è¯†åº“åŠ©æ‰‹ã€‚ä½ çš„é£æ ¼åº”è¯¥ï¼š
- è‡ªç„¶äº²åˆ‡ï¼Œåƒåœ¨å’Œæœ‹å‹èŠå¤©
- ä¸“ä¸šä½†ä¸ç”Ÿç¡¬
- ä¹äºåŠ©äººä¸”æœ‰è€å¿ƒ
- æ ¹æ®ä¸Šä¸‹æ–‡é€‚å½“å‘æŒ¥ï¼Œè®©å›ç­”æ›´å®Œæ•´

# å¯ç”¨ä¿¡æ¯
ä»¥ä¸‹æ˜¯ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

# å¯¹è¯èƒŒæ™¯
ä¹‹å‰çš„å¯¹è¯ï¼š
{history}

# å½“å‰é—®é¢˜
ç”¨æˆ·é—®ï¼š{question}

# å›ç­”è¦æ±‚
1. åŸºäºçŸ¥è¯†åº“å†…å®¹ï¼Œç”¨è‡ªç„¶çš„ä¸­æ–‡å›ç­”
2. å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯å……åˆ†ï¼Œè¯·è‡ªä¿¡åœ°å›ç­”å¹¶æ³¨æ˜æ¥æºã€æ–‡æ¡£Xã€‘
3. å¦‚æœä¿¡æ¯ä¸å®Œæ•´ï¼Œå¯ä»¥ç»“åˆå¸¸è¯†è¡¥å……ï¼Œä½†è¦è¯´æ˜å“ªäº›æ˜¯çŸ¥è¯†åº“å†…å®¹ï¼Œå“ªäº›æ˜¯ä½ çš„è¡¥å……
4. å›ç­”è¦æµç•…ï¼Œé¿å…æœºæ¢°åœ°å¤åˆ¶ç²˜è´´
5. é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·è®©å¯¹è¯æ›´ç”ŸåŠ¨ï¼ˆä½†ä¸è¦è¿‡åº¦ï¼‰

# å¼•ç”¨è®°å½•ï¼ˆè¿™éƒ¨åˆ†ä¸ä¼šæ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
è¯·åœ¨å›ç­”åè®°å½•å®é™…å¼•ç”¨çš„å†…å®¹ï¼š

ã€å®é™…å¼•ç”¨å†…å®¹ã€‘
æ–‡æ¡£X: å…·ä½“å¼•ç”¨çš„æ–‡æœ¬

ç°åœ¨è¯·å¼€å§‹å›ç­”ï¼š
""")

        # æ ¼å¼åŒ–å¯¹è¯å†å²
        history_text = "\n".join([
            f"{msg['role']}: {msg['content']}"
            for msg in state.conversation_history[-5:]
        ])

        # è°ƒç”¨LLMç”Ÿæˆå›ç­”
        chain = prompt | self.llm | StrOutputParser()
        full_response = chain.invoke({
            "context": context,
            "history": history_text,
            "question": state.question
        })

        print(f"ğŸ” LLMåŸå§‹å“åº”: {full_response}")  # è°ƒè¯•ç”¨

        # åˆ†ç¦»å›ç­”å’Œå®é™…å¼•ç”¨å†…å®¹
        answer, actual_citations = self._parse_response(full_response)

        # å¦‚æœæ²¡æœ‰è§£æåˆ°å¼•ç”¨ï¼Œä½¿ç”¨å›é€€æ–¹æ³•
        if not actual_citations:
            actual_citations = self._fallback_extract_citations(answer, state.retrieved_docs, state.question)

        # æ„å»ºå¼•ç”¨ä¿¡æ¯
        citations = self._build_citations_from_actual_usage(actual_citations, state.retrieved_docs)

        return {
            "answer": answer,
            "citations": citations
        }

    def _parse_response(self, full_response: str) -> tuple[str, List[Dict]]:
        """è§£æLLMçš„å®Œæ•´å“åº”ï¼Œåˆ†ç¦»å›ç­”å’Œå®é™…å¼•ç”¨å†…å®¹"""
        # æŸ¥æ‰¾å®é™…å¼•ç”¨å†…å®¹æ ‡è®°
        citation_marker = "ã€å®é™…å¼•ç”¨å†…å®¹ã€‘"
        if citation_marker in full_response:
            parts = full_response.split(citation_marker)
            answer = parts[0].strip()
            citation_text = parts[1].strip()

            # è§£æå¼•ç”¨å†…å®¹
            actual_citations = []
            lines = citation_text.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('æ–‡æ¡£') and ':' in line:
                    try:
                        doc_part, content = line.split(':', 1)
                        doc_id = int(doc_part.replace('æ–‡æ¡£', '').strip())
                        actual_citations.append({
                            'doc_id': doc_id,
                            'content': content.strip()
                        })
                    except ValueError:
                        continue  # è·³è¿‡è§£æå¤±è´¥çš„è¡Œ

            return answer, actual_citations
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®æ ‡è®°ï¼Œè¿”å›æ•´ä¸ªå“åº”ä½œä¸ºå›ç­”
            return full_response, []

    def _fallback_extract_citations(self, answer: str, documents: List[Document], question: str) -> List[Dict]:
        """å›é€€æ–¹æ³•ï¼šä»å›ç­”ä¸­æå–å¼•ç”¨ä¿¡æ¯"""
        citations = []

        for i, doc in enumerate(documents):
            if f"ã€æ–‡æ¡£{i + 1}ã€‘" in answer:
                # åœ¨æ–‡æ¡£å†…å®¹ä¸­æŸ¥æ‰¾ä¸é—®é¢˜æœ€ç›¸å…³çš„å†…å®¹
                relevant_content = self._find_relevant_content(doc.page_content, question)

                citations.append({
                    'doc_id': i + 1,
                    'content': relevant_content
                })

        return citations

    def _find_relevant_content(self, content: str, question: str) -> str:
        """åœ¨æ–‡æ¡£å†…å®¹ä¸­æ‰¾åˆ°ä¸é—®é¢˜æœ€ç›¸å…³çš„å†…å®¹"""
        import re

        # æå–é—®é¢˜å…³é”®è¯
        question_clean = re.sub(r'[^\w\s]', '', question.lower())
        keywords = [word for word in question_clean.split() if len(word) > 1]

        if not keywords:
            return content[:200] + ('...' if len(content) > 200 else '')

        # æŒ‰å¥å­åˆ†å‰²
        sentences = [s.strip() for s in content.split('ã€‚') if s.strip()]

        # æ‰¾åˆ°åŒ…å«å…³é”®è¯çš„å¥å­
        relevant_sentences = []
        for sentence in sentences:
            sentence_lower = sentence.lower()
            if any(keyword in sentence_lower for keyword in keywords):
                relevant_sentences.append(sentence)
                if len('ã€‚'.join(relevant_sentences)) > 150:
                    break

        if relevant_sentences:
            return 'ã€‚'.join(relevant_sentences) + 'ã€‚'
        else:
            # è¿”å›å†…å®¹å¼€å¤´
            return content[:150] + ('...' if len(content) > 150 else '')

    def _build_citations_from_actual_usage(self, actual_citations: List[Dict], documents: List[Document]) -> List[Dict]:
        """æ ¹æ®LLMå®é™…ä½¿ç”¨çš„å†…å®¹æ„å»ºå¼•ç”¨ä¿¡æ¯"""
        citations = []

        for citation in actual_citations:
            doc_id = citation['doc_id']
            if 1 <= doc_id <= len(documents):
                doc = documents[doc_id - 1]
                citations.append({
                    "doc_id": doc_id,
                    "content": citation['content'],
                    "metadata": doc.metadata
                })

        return citations

    def chat(self, question: str, conversation_id: str = "default") -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·é—®é¢˜"""
        # è·å–å¯¹è¯å†å²
        history = self.conversation_manager.get_conversation_history(conversation_id)

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = ChatState(
            question=question,
            conversation_history=history
        )

        # æ‰§è¡Œå·¥ä½œæµ
        result = self.workflow.invoke(initial_state)

        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_manager.add_message(conversation_id, "user", question)
        self.conversation_manager.add_message(
            conversation_id,
            "assistant",
            result["answer"],
            {"citations": result["citations"]}
        )

        return {
            "answer": result["answer"],
            "citations": result["citations"],
            "retrieved_docs": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in result["retrieved_docs"]
            ]
        }"" 
